{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korean Tokenizer 학습\n",
    "\n",
    "210319\n",
    "\n",
    "huggingface의 tokenizers를 이용해서 한글 tokenizer를 학습한다\n",
    "\n",
    "tokenizer에 special_tokens는 굉장히 중요하다.\n",
    "\n",
    "하지만 tokenizers로 학습시 special_tokens를 추가하지만\n",
    "\n",
    "transformers에서 load할 때 반영되지 않는다\n",
    "\n",
    "그래서 transformers에서 load 후 special_tokens를 추가하고 저장하면 load 가능하다\n",
    "\n",
    "tokenizers와 transformers 사이의 매끄러운 연결 구현이 huggingface에 잘 안되있다\n",
    "\n",
    "억지로 되게 만들었다\n",
    "\n",
    "\n",
    "### 주의!!\n",
    "BertWordPieceTokenizer 학습 시 한국어는 strip_accents를 False로 해줘야 한다\n",
    "\n",
    "만약 True일 시 나는 -> 'ㄴ','ㅏ','ㄴ','ㅡ','ㄴ' 로 쪼개져서 처리된다\n",
    "\n",
    "학습시 False했으므로 load할 때도 False를 꼭 확인해야 한다\n",
    "\n",
    "\n",
    "- [keep steady](https://keep-steady.tistory.com/37?category=702926)\n",
    "- [transformers](https://github.com/huggingface/transformers/blob/master/notebooks/02-transformers.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 설치(210319 최신버전)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# setup\n",
    "!pip install transformers==4.4.1\n",
    "!pip install tokenizers==0.10.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. mecab 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['어릴때보고 지금다시봐도 재밌어요ㅋㅋ', '디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업이 부러웠는데. 사실 우리나라에서도 그 어려운시절에 끝까지 열정을 지킨 노라노 같은 전통이있어 저와 같은 사람들이 꿈을 꾸고 이뤄나갈 수 있다는 것에 감사합니다.', '폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.']\n"
     ]
    }
   ],
   "source": [
    "# load korean corpus for tokenizer training\n",
    "with open('data/train_tokenizer.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read().split('\\n')\n",
    "print(data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     16
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mecab check : ['어릴', '때', '보', '고', '지금', '다시', '봐도', '재밌', '어요', 'ㅋㅋ']\n",
      "[['어릴', '때', '보', '고', '지금', '다시', '봐도', '재밌', '어요', 'ㅋㅋ'], ['디자인', '을', '배우', '는', '학생', '으로', ',', '외국', '디자이너', '와', '그', '들', '이', '일군', '전통', '을', '통해', '발전', '해', '가', '는', '문화', '산업', '이', '부러웠', '는데', '.', '사실', '우리', '나라', '에서', '도', '그', '어려운', '시절', '에', '끝', '까지', '열정', '을', '지킨', '노라노', '같', '은', '전통', '이', '있', '어', '저', '와', '같', '은', '사람', '들', '이', '꿈', '을', '꾸', '고', '이뤄나갈', '수', '있', '다는', '것', '에', '감사', '합니다', '.'], ['폴리스', '스토리', '시리즈', '는', '1', '부터', '뉴', '까지', '버릴', '께', '하나', '도', '없', '음', '.', '.', '최고', '.']]\n",
      "199993\n",
      "Wall time: 19.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# mecab for window는 아래 코드 사용\n",
    "from konlpy.tag import Mecab  # install mecab for window: https://hong-yp-ml-records.tistory.com/91\n",
    "mecab_tokenizer = Mecab(dicpath=r\"C:\\mecab\\mecab-ko-dic\").morphs\n",
    "print('mecab check :', mecab_tokenizer('어릴때보고 지금다시봐도 재밌어요ㅋㅋ'))\n",
    "\n",
    "# 1: '어릴때' -> '어릴, ##때' for generation model\n",
    "# 2: '어릴때' -> '어릴, 때'   for normal case\n",
    "\n",
    "# ['어릴', '때', '보', '고', '지금', '다시', '봐도', '재밌', '어요', 'ㅋㅋ']\n",
    "# ['어릴', '##때', '##보', '##고', '##지금', '##다시', '##봐도', '##재밌', '##어요', '##ㅋㅋ']\n",
    "\n",
    "for_generation = False # or normal\n",
    "\n",
    "if for_generation:\n",
    "    # 1: '어릴때' -> '어릴, ##때' for generation model\n",
    "    total_morph=[]\n",
    "    for sentence in data:\n",
    "        # 문장단위 mecab 적용\n",
    "        morph_sentence= []\n",
    "        count = 0\n",
    "        for token_mecab in mecab_tokenizer(sentence):\n",
    "            token_mecab_save = token_mecab\n",
    "            if count > 0:\n",
    "                token_mecab_save = \"##\" + token_mecab_save  # 앞에 ##를 부친다\n",
    "                morph_sentence.append(token_mecab_save)\n",
    "            else:\n",
    "                morph_sentence.append(token_mecab_save)\n",
    "                count += 1\n",
    "        # 문장단위 저장\n",
    "        total_morph.append(morph_sentence)\n",
    "\n",
    "else:\n",
    "    # 2: '어릴때' -> '어릴, 때'   for normal case\n",
    "    total_morph=[]\n",
    "    for sentence in data:\n",
    "        # 문장단위 mecab 적용\n",
    "        morph_sentence= mecab_tokenizer(sentence)\n",
    "        # 문장단위 저장\n",
    "        total_morph.append(morph_sentence)\n",
    "                        \n",
    "print(total_morph[:3])\n",
    "print(len(total_morph))\n",
    "\n",
    "# mecab 적용한 데이터 저장\n",
    "# ex) 1 line: '어릴 때 보 고 지금 다시 봐도 재밌 어요 ㅋㅋ'\n",
    "with open('data/after_mecab.txt', 'w', encoding='utf-8') as f:\n",
    "    for line in total_morph:\n",
    "        f.write(' '.join(line)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Tokenizer\n",
    "\n",
    "downstream task를 위해 UNK와 많은 unused가 필요하다.\n",
    "\n",
    "1) define special tokens\n",
    "\n",
    "2) train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[BOS]', '[EOS]', '[UNK0]', '[UNK1]', '[UNK2]', '[UNK3]', '[UNK4]', '[UNK5]', '[UNK6]', '[UNK7]', '[UNK8]', '[UNK9]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]', '[unused49]', '[unused50]', '[unused51]', '[unused52]', '[unused53]', '[unused54]', '[unused55]', '[unused56]', '[unused57]', '[unused58]', '[unused59]', '[unused60]', '[unused61]', '[unused62]', '[unused63]', '[unused64]', '[unused65]', '[unused66]', '[unused67]', '[unused68]', '[unused69]', '[unused70]', '[unused71]', '[unused72]', '[unused73]', '[unused74]', '[unused75]', '[unused76]', '[unused77]', '[unused78]', '[unused79]', '[unused80]', '[unused81]', '[unused82]', '[unused83]', '[unused84]', '[unused85]', '[unused86]', '[unused87]', '[unused88]', '[unused89]', '[unused90]', '[unused91]', '[unused92]', '[unused93]', '[unused94]', '[unused95]', '[unused96]', '[unused97]', '[unused98]', '[unused99]', '[unused100]', '[unused101]', '[unused102]', '[unused103]', '[unused104]', '[unused105]', '[unused106]', '[unused107]', '[unused108]', '[unused109]', '[unused110]', '[unused111]', '[unused112]', '[unused113]', '[unused114]', '[unused115]', '[unused116]', '[unused117]', '[unused118]', '[unused119]', '[unused120]', '[unused121]', '[unused122]', '[unused123]', '[unused124]', '[unused125]', '[unused126]', '[unused127]', '[unused128]', '[unused129]', '[unused130]', '[unused131]', '[unused132]', '[unused133]', '[unused134]', '[unused135]', '[unused136]', '[unused137]', '[unused138]', '[unused139]', '[unused140]', '[unused141]', '[unused142]', '[unused143]', '[unused144]', '[unused145]', '[unused146]', '[unused147]', '[unused148]', '[unused149]', '[unused150]', '[unused151]', '[unused152]', '[unused153]', '[unused154]', '[unused155]', '[unused156]', '[unused157]', '[unused158]', '[unused159]', '[unused160]', '[unused161]', '[unused162]', '[unused163]', '[unused164]', '[unused165]', '[unused166]', '[unused167]', '[unused168]', '[unused169]', '[unused170]', '[unused171]', '[unused172]', '[unused173]', '[unused174]', '[unused175]', '[unused176]', '[unused177]', '[unused178]', '[unused179]', '[unused180]', '[unused181]', '[unused182]', '[unused183]', '[unused184]', '[unused185]', '[unused186]', '[unused187]', '[unused188]', '[unused189]', '[unused190]', '[unused191]', '[unused192]', '[unused193]', '[unused194]', '[unused195]', '[unused196]', '[unused197]', '[unused198]', '[unused199]']\n"
     ]
    }
   ],
   "source": [
    "## 1) define special tokens\n",
    "user_defined_symbols = ['[BOS]','[EOS]','[UNK0]','[UNK1]','[UNK2]','[UNK3]','[UNK4]','[UNK5]','[UNK6]','[UNK7]','[UNK8]','[UNK9]']\n",
    "unused_token_num = 200\n",
    "unused_list = ['[unused{}]'.format(n) for n in range(unused_token_num)]\n",
    "user_defined_symbols = user_defined_symbols + unused_list\n",
    "\n",
    "print(user_defined_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertWordPieceTokenizer\n",
      "train complete\n",
      "나는 오늘 아침밥을 먹었다.\n",
      "=>tokens: ['나', '##는', '오늘', '아침', '##밥', '##을', '먹', '##었다', '.']\n",
      "=>idx   : [875, 3288, 5446, 6142, 3380, 3653, 1474, 17171, 18]\n",
      "=>offset: [(0, 1), (1, 2), (3, 5), (6, 8), (8, 9), (9, 10), (11, 12), (12, 14), (14, 15)]\n",
      "=>decode: 나는 오늘 아침밥을 먹었다.\n",
      "\n",
      "I want to go my hometown\n",
      "=>tokens: ['I', 'want', 'to', 'go', 'my', 'h', '##ome', '##t', '##own']\n",
      "=>idx   : [45, 17424, 7701, 11757, 10072, 76, 11902, 3315, 22586]\n",
      "=>offset: [(0, 1), (2, 6), (7, 9), (10, 12), (13, 15), (16, 17), (17, 20), (20, 21), (21, 24)]\n",
      "=>decode: I want to go my hometown\n",
      "\n",
      "Wall time: 6.93 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tokenizer_model\\\\vocab.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## 2) train\n",
    "import os\n",
    "from tokenizers import BertWordPieceTokenizer, SentencePieceBPETokenizer, CharBPETokenizer, ByteLevelBPETokenizer\n",
    "\n",
    "# 4가지중 tokenizer 선택\n",
    "how_to_tokenize = BertWordPieceTokenizer  # The famous Bert tokenizer, using WordPiece\n",
    "# how_to_tokenize = SentencePieceBPETokenizer  # A BPE implementation compatible with the one used by SentencePiece\n",
    "# how_to_tokenize = CharBPETokenizer  # The original BPE\n",
    "# how_to_tokenize = ByteLevelBPETokenizer  # The byte level version of the BPE\n",
    "\n",
    "# Initialize a tokenizer\n",
    "if str(how_to_tokenize) == str(BertWordPieceTokenizer):\n",
    "    print('BertWordPieceTokenizer')\n",
    "    ## 주의!! 한국어는 strip_accents를 False로 해줘야 한다\n",
    "    # 만약 True일 시 나는 -> 'ㄴ','ㅏ','ㄴ','ㅡ','ㄴ' 로 쪼개져서 처리된다\n",
    "    # 학습시 False했으므로 load할 때도 False를 꼭 확인해야 한다\n",
    "    tokenizer = BertWordPieceTokenizer(strip_accents=False,  # Must be False if cased model\n",
    "                                       lowercase=False)\n",
    "elif str(how_to_tokenize) == str(SentencePieceBPETokenizer):\n",
    "    print('SentencePieceBPETokenizer')\n",
    "    tokenizer = SentencePieceBPETokenizer()\n",
    "\n",
    "elif str(how_to_tokenize) == str(CharBPETokenizer):\n",
    "    print('CharBPETokenizer')\n",
    "    tokenizer = CharBPETokenizer()\n",
    "    \n",
    "elif str(how_to_tokenize) == str(ByteLevelBPETokenizer):\n",
    "    print('ByteLevelBPETokenizer')\n",
    "    tokenizer = ByteLevelBPETokenizer()\n",
    "       \n",
    "else:\n",
    "    assert('select right tokenizer')\n",
    "\n",
    "#########################################\n",
    "corpus_file   = ['data/after_mecab.txt']  # data path\n",
    "vocab_size    = 32000\n",
    "limit_alphabet= 6000\n",
    "output_path   = 'hugging_%d'%(vocab_size)\n",
    "min_frequency = 5\n",
    "\n",
    "# Then train it!\n",
    "tokenizer.train(files=corpus_file,\n",
    "               vocab_size=vocab_size,\n",
    "               min_frequency=min_frequency,  # 단어의 최소 발생 빈도, 5\n",
    "               limit_alphabet=limit_alphabet,  # ByteLevelBPETokenizer 학습시엔 주석처리 필요\n",
    "               show_progress=True)\n",
    "print('train complete')\n",
    "\n",
    "sentence = '나는 오늘 아침밥을 먹었다.'\n",
    "output = tokenizer.encode(sentence)\n",
    "print(sentence)\n",
    "print('=>tokens: %s'%output.tokens)\n",
    "print('=>idx   : %s'%output.ids)\n",
    "print('=>offset: %s'%output.offsets)\n",
    "print('=>decode: %s\\n'%tokenizer.decode(output.ids))\n",
    "\n",
    "sentence = 'I want to go my hometown'\n",
    "output = tokenizer.encode(sentence)\n",
    "print(sentence)\n",
    "print('=>tokens: %s'%output.tokens)\n",
    "print('=>idx   : %s'%output.ids)\n",
    "print('=>offset: %s'%output.offsets)\n",
    "print('=>decode: %s\\n'%tokenizer.decode(output.ids))\n",
    "\n",
    "# save tokenizer\n",
    "hf_model_path='tokenizer_model'\n",
    "if not os.path.isdir(hf_model_path):\n",
    "    os.mkdir(hf_model_path)\n",
    "tokenizer.save_model(hf_model_path)  # vocab.txt 파일 한개가 만들어진다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check import tokenizer from Transformers\n",
    "\n",
    "BertTokenizerFast 는 학습한 환경과 똑같이 strip_accents=False 로 줘야한다\n",
    "\n",
    "True로 주면 '나는'->'ㄴㅏㄴㅡㄴ' 과 같이 쪼개져서 인식해서 안된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size : 27305\n",
      "Tokens (str)      : ['[CLS]', '나', '##는', '오늘', '아침', '##밥', '##을', '먹', '##었다', '.', '[SEP]']\n",
      "Tokens (int)      : [2, 875, 3288, 5446, 6142, 3380, 3653, 1474, 17171, 18, 3]\n",
      "Tokens (attn_mask): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer_for_load = BertTokenizerFast.from_pretrained(hf_model_path,\n",
    "                                                       strip_accents=False,  # Must be False if cased model\n",
    "                                                       lowercase=False)  # 로드\n",
    "\n",
    "print('vocab size : %d' % tokenizer_for_load.vocab_size)\n",
    "# tokenized_input_for_pytorch = tokenizer_for_load(\"i am very hungry\", return_tensors=\"pt\")\n",
    "tokenized_input_for_pytorch = tokenizer_for_load(\"나는 오늘 아침밥을 먹었다.\", return_tensors=\"pt\")\n",
    "tokenized_input_for_tensorflow = tokenizer_for_load(\"나는 오늘 아침밥을 먹었다.\", return_tensors=\"tf\")\n",
    "\n",
    "print(\"Tokens (str)      : {}\".format([tokenizer_for_load.convert_ids_to_tokens(s) for s in tokenized_input_for_pytorch['input_ids'].tolist()[0]]))\n",
    "print(\"Tokens (int)      : {}\".format(tokenized_input_for_pytorch['input_ids'].tolist()[0]))\n",
    "print(\"Tokens (attn_mask): {}\\n\".format(tokenized_input_for_pytorch['attention_mask'].tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'##わ': 4236,\n",
       " '2013': 8497,\n",
       " '머시': 25259,\n",
       " '##저릿': 24079,\n",
       " '해짐': 8888,\n",
       " '확확': 22252,\n",
       " '권리': 10850,\n",
       " '도저': 5773,\n",
       " 'ㅇㅋㅋ': 24854,\n",
       " '인생': 5224,\n",
       " '베껴': 13087,\n",
       " '딜레마': 15600,\n",
       " '뢔': 1374,\n",
       " '##베이터': 13207,\n",
       " '뽑아낸': 27018,\n",
       " '##난다': 5778,\n",
       " '저능아': 12105,\n",
       " '남겨요': 16591,\n",
       " '셸': 1898,\n",
       " '쉣': 1950,\n",
       " '바늘': 17592,\n",
       " '올려': 6459,\n",
       " '##하하': 5934,\n",
       " '욕정': 17704,\n",
       " '##제네거': 18754,\n",
       " '괜찮': 5212,\n",
       " '일수록': 17739,\n",
       " 'CD': 16722,\n",
       " '류헤이': 25218,\n",
       " '아파지': 26667,\n",
       " '피아': 7408,\n",
       " '지상': 7895,\n",
       " '연기': 5117,\n",
       " '텐': 2891,\n",
       " '인간': 5248,\n",
       " '뒤엎': 18297,\n",
       " 'have': 20143,\n",
       " '##스크': 7873,\n",
       " '사골': 11627,\n",
       " '쨩': 2556,\n",
       " '아델': 21859,\n",
       " '이완용': 26824,\n",
       " '덱스터': 17532,\n",
       " '드만': 8616,\n",
       " '부': 1682,\n",
       " '컴퓨터': 7215,\n",
       " '워낭': 15825,\n",
       " '뮬란': 14390,\n",
       " '재주': 9329,\n",
       " '률': 1403,\n",
       " '그땐': 11421,\n",
       " '×': 109,\n",
       " '옆집': 13136,\n",
       " '웟다': 14849,\n",
       " '잡쳐': 25843,\n",
       " '엉터리': 9008,\n",
       " '히말라야': 21341,\n",
       " '##꼰': 5038,\n",
       " '##수정': 8598,\n",
       " '亡': 336,\n",
       " '백마': 23340,\n",
       " '발칙': 12599,\n",
       " '개욕': 24890,\n",
       " '커져': 23845,\n",
       " '자신': 5423,\n",
       " '엘리': 7687,\n",
       " '던진다': 21571,\n",
       " '교정': 24946,\n",
       " '졌': 2423,\n",
       " '##크ㅋ': 22294,\n",
       " '픽픽': 23942,\n",
       " '졸려': 8722,\n",
       " '칫': 2741,\n",
       " '테러리스트': 11894,\n",
       " '마의': 14751,\n",
       " '됬': 1131,\n",
       " '##ure': 26339,\n",
       " '않': 2115,\n",
       " '엋': 2175,\n",
       " '압권': 6279,\n",
       " '콸': 2809,\n",
       " '압구': 21868,\n",
       " '핑계': 12676,\n",
       " '이즘': 25802,\n",
       " '듭니다': 7194,\n",
       " '눈요깃거리': 26837,\n",
       " '젖': 2406,\n",
       " '아파': 7012,\n",
       " '26': 10968,\n",
       " '길이': 14707,\n",
       " '##급': 3482,\n",
       " '짇': 2516,\n",
       " '스러워서': 10136,\n",
       " '모지': 10866,\n",
       " '능': 1009,\n",
       " '메기': 16242,\n",
       " '타당': 19622,\n",
       " '상수': 21782,\n",
       " '넌센스': 25045,\n",
       " '##웨인': 18784,\n",
       " '퉁': 2918,\n",
       " '통한': 10793,\n",
       " '마땅': 9744,\n",
       " '이동': 7689,\n",
       " '##곀': 3599,\n",
       " '##정원': 13821,\n",
       " '짜여': 14490,\n",
       " '##항': 3795,\n",
       " '지망생': 18942,\n",
       " '만이': 25236,\n",
       " '봅': 1653,\n",
       " '쿨러닝': 26037,\n",
       " '##웁니다': 19794,\n",
       " 'ㅡㅡ아': 13518,\n",
       " '˚': 111,\n",
       " '괜히': 5890,\n",
       " '외로움': 8552,\n",
       " '킬미': 23868,\n",
       " '스타게이트': 26513,\n",
       " '당분간': 17381,\n",
       " '냐구요': 25043,\n",
       " '영미': 25689,\n",
       " '하리수': 19666,\n",
       " '##벌레': 13499,\n",
       " '상': 1826,\n",
       " '”': 118,\n",
       " '흐느끼': 22753,\n",
       " '영계': 25688,\n",
       " '##en': 7281,\n",
       " '##수리': 11698,\n",
       " '잠재': 12004,\n",
       " '소재': 5235,\n",
       " '삽니다': 18408,\n",
       " '꼼수': 20243,\n",
       " '상실감': 22591,\n",
       " '모히칸': 27235,\n",
       " '고군': 13593,\n",
       " '웃겨요': 9101,\n",
       " '거금': 24901,\n",
       " '오그라': 6652,\n",
       " '숨겨': 6875,\n",
       " '비추': 5932,\n",
       " '##요보비치': 13829,\n",
       " '돼': 1118,\n",
       " '세훈': 25491,\n",
       " '##투': 3673,\n",
       " '##유미': 9268,\n",
       " '신기원': 26559,\n",
       " '3000': 19054,\n",
       " '히어로': 6363,\n",
       " '합쳐': 10566,\n",
       " '더군': 7836,\n",
       " '뜨거워지': 18943,\n",
       " '바쳤': 25321,\n",
       " '##혜': 3759,\n",
       " '프롤': 26125,\n",
       " '##뻥': 3641,\n",
       " '천재': 5876,\n",
       " '엠마': 8719,\n",
       " '##니트': 10580,\n",
       " '##매매': 14186,\n",
       " '자화': 13154,\n",
       " '잔치': 12425,\n",
       " '뜯': 1271,\n",
       " '틱하': 16459,\n",
       " '타자': 19621,\n",
       " '깜작': 23067,\n",
       " '끄집': 19165,\n",
       " '의서': 20609,\n",
       " 'ㅇㅅ': 10715,\n",
       " '이가흔': 21258,\n",
       " '들려': 8927,\n",
       " '탐정': 12217,\n",
       " '원제목': 22635,\n",
       " '휴전': 26219,\n",
       " '대작': 5875,\n",
       " '눈썹': 16198,\n",
       " '애로': 19418,\n",
       " '차마': 9146,\n",
       " '##uch': 24108,\n",
       " '기관': 11423,\n",
       " '터널': 14134,\n",
       " '느낄': 5652,\n",
       " '반한': 14766,\n",
       " '말초': 17562,\n",
       " '##딱': 3483,\n",
       " '섞': 1856,\n",
       " '범주': 21721,\n",
       " '고증': 7878,\n",
       " '遠': 541,\n",
       " '븐': 1709,\n",
       " '용화': 21944,\n",
       " '마조': 23221,\n",
       " '##sf': 24098,\n",
       " '례': 1355,\n",
       " '목수': 25288,\n",
       " '차순': 25957,\n",
       " '브라운': 12978,\n",
       " '맞먹': 10512,\n",
       " '뺴고': 16291,\n",
       " '괴로울': 24432,\n",
       " '다를': 6970,\n",
       " '김동완': 14629,\n",
       " '창피': 7983,\n",
       " '##TL': 16546,\n",
       " '우동': 16987,\n",
       " '창시자': 24713,\n",
       " '##어들': 12238,\n",
       " '명성황후': 26629,\n",
       " '촹': 2692,\n",
       " '챤': 2650,\n",
       " '아나키': 21077,\n",
       " 'feel': 22761,\n",
       " '착한데': 26627,\n",
       " '다크니스': 26671,\n",
       " '##펜스': 9501,\n",
       " '슬프': 5433,\n",
       " '못생겼': 9965,\n",
       " '휴잇': 17883,\n",
       " '##x': 3616,\n",
       " '##벤처': 15017,\n",
       " '다친': 23125,\n",
       " '흉터': 24005,\n",
       " '빵': 1738,\n",
       " '필살기': 27292,\n",
       " '각오': 15165,\n",
       " '##어쓰': 19729,\n",
       " '스턴트': 18951,\n",
       " '냉장': 17505,\n",
       " '닶': 1041,\n",
       " '에다가': 7538,\n",
       " '현상': 10041,\n",
       " '##뛰': 4052,\n",
       " '부셔버릴': 24543,\n",
       " '##라고': 6290,\n",
       " '으루': 12884,\n",
       " '어쩐': 10297,\n",
       " '민비': 15255,\n",
       " '중학': 17049,\n",
       " '코끝': 15400,\n",
       " '삭막': 15285,\n",
       " '##hen': 16583,\n",
       " '##민수': 19775,\n",
       " '##하면': 9861,\n",
       " '고교': 14690,\n",
       " '놈': 960,\n",
       " '##즉': 4762,\n",
       " '케이스': 10596,\n",
       " '이걸': 5311,\n",
       " '협력': 22238,\n",
       " '존스': 7845,\n",
       " '하이라이트': 11895,\n",
       " '무자': 14013,\n",
       " '갈기갈기': 24540,\n",
       " 'L': 48,\n",
       " '##략': 4108,\n",
       " '젇': 2397,\n",
       " '##존': 3760,\n",
       " '하차': 9566,\n",
       " '넵': 938,\n",
       " '저릿': 18556,\n",
       " '챨': 2652,\n",
       " '윤시윤': 11749,\n",
       " '미지근': 12989,\n",
       " '먼로': 23265,\n",
       " '황정민': 8502,\n",
       " '기나': 24972,\n",
       " '펑': 2980,\n",
       " '설국': 16911,\n",
       " '한물갔': 21155,\n",
       " '일생': 8881,\n",
       " '나간다': 13044,\n",
       " '탭': 2873,\n",
       " '근래': 6880,\n",
       " '단어': 6926,\n",
       " '바야': 15743,\n",
       " '하수': 17102,\n",
       " '##c': 3358,\n",
       " '조지': 8104,\n",
       " '해야': 5347,\n",
       " '새낀': 23420,\n",
       " '대충': 6099,\n",
       " '품': 3019,\n",
       " '오마이': 12988,\n",
       " '뛴': 1262,\n",
       " '섭리': 23445,\n",
       " '지진희': 10313,\n",
       " '미사일': 12292,\n",
       " '##라이더': 18814,\n",
       " '규정': 23039,\n",
       " '구원': 9110,\n",
       " '짊어지': 23779,\n",
       " '착오': 14122,\n",
       " '어느덧': 15035,\n",
       " '그리도': 13848,\n",
       " '젹': 2417,\n",
       " '닿': 1049,\n",
       " '여러모로': 8161,\n",
       " '차기': 9486,\n",
       " '##js': 20938,\n",
       " '##즈미': 26246,\n",
       " '돼지고기': 26690,\n",
       " '거덩': 21414,\n",
       " '인한': 8880,\n",
       " '뼈': 1769,\n",
       " '콧': 2801,\n",
       " '어찌': 6072,\n",
       " '##샌': 4343,\n",
       " '어설픔': 10137,\n",
       " '되돌아보': 10827,\n",
       " '용두': 9396,\n",
       " '주제가': 11885,\n",
       " '##학자': 15454,\n",
       " '불협화음': 16697,\n",
       " '눈가': 16794,\n",
       " '공권': 18220,\n",
       " '스푼': 18435,\n",
       " '눈사태': 23116,\n",
       " '겨운': 24916,\n",
       " '둬': 1145,\n",
       " '시킨': 6252,\n",
       " '급한': 19139,\n",
       " '붜': 1695,\n",
       " '배창호': 16709,\n",
       " '위조': 19477,\n",
       " '관능미': 22677,\n",
       " '감방': 16739,\n",
       " '에바': 8675,\n",
       " '밖엔': 10872,\n",
       " '섞이': 17638,\n",
       " '##3': 3337,\n",
       " '션': 1889,\n",
       " '##거': 3372,\n",
       " '일치': 12894,\n",
       " '괜찬았': 21102,\n",
       " '더': 1069,\n",
       " '##IF': 24143,\n",
       " '번호': 15751,\n",
       " '할라': 17105,\n",
       " '고라': 22995,\n",
       " '##쵝오': 26327,\n",
       " '곁들여': 20194,\n",
       " '머물': 12366,\n",
       " '한인': 26152,\n",
       " '뱀파이어': 7252,\n",
       " '바이크': 23309,\n",
       " '흘려': 13467,\n",
       " '##닛': 4434,\n",
       " '피티': 16467,\n",
       " '눈살': 12566,\n",
       " '##재미있': 19959,\n",
       " '이정현': 10601,\n",
       " '줠': 2481,\n",
       " '독수리': 14358,\n",
       " '현시': 20808,\n",
       " '오정세': 12534,\n",
       " '##타클': 10684,\n",
       " '숲': 1939,\n",
       " '##철수': 20935,\n",
       " '명령': 25278,\n",
       " '쫙쫙': 23791,\n",
       " '선입': 10396,\n",
       " '오산': 15814,\n",
       " '동영상': 7493,\n",
       " '당한': 7248,\n",
       " '강동원': 7791,\n",
       " '들리': 8926,\n",
       " '정재': 9079,\n",
       " '##ect': 13818,\n",
       " '윤두준': 19012,\n",
       " '##mer': 24051,\n",
       " '##간장': 26364,\n",
       " '도신': 13985,\n",
       " '얼굴': 5532,\n",
       " '##맘때': 26460,\n",
       " '##ㅋㅋㅋㅋㅋㅋㅋㅋ': 7185,\n",
       " '##렬': 4121,\n",
       " '아이씨': 26482,\n",
       " '아드레': 19412,\n",
       " '“': 117,\n",
       " '춤추': 8835,\n",
       " '겨울': 6496,\n",
       " '밀회': 25317,\n",
       " '##현실': 15458,\n",
       " '샵': 1847,\n",
       " '코리아': 14925,\n",
       " '주류': 15867,\n",
       " '꽉': 810,\n",
       " '킬링': 5460,\n",
       " '며': 1494,\n",
       " '가족': 5292,\n",
       " '##디어': 6109,\n",
       " '##쪽': 3670,\n",
       " '엄정화': 8084,\n",
       " '요': 2258,\n",
       " '중요': 5745,\n",
       " '나눠': 9893,\n",
       " '김윤석': 12288,\n",
       " '간지': 7310,\n",
       " '감춰': 13585,\n",
       " '어짜': 14832,\n",
       " '오구리': 15338,\n",
       " '##언정': 16548,\n",
       " '창조': 9487,\n",
       " '그은': 13600,\n",
       " '임수정': 9401,\n",
       " '라니까': 16565,\n",
       " '속하': 18422,\n",
       " '비웃음': 19344,\n",
       " '할애': 22214,\n",
       " '◐': 167,\n",
       " '송일국': 15122,\n",
       " '위선자': 22658,\n",
       " '##봤': 3982,\n",
       " '글리': 23045,\n",
       " '유란': 23654,\n",
       " '이라든지': 24402,\n",
       " '마틴스콜세지': 24794,\n",
       " '원주민': 15537,\n",
       " 'Oh': 17414,\n",
       " '무언가': 6608,\n",
       " '치중': 11055,\n",
       " '래빗': 21613,\n",
       " '호타루': 19017,\n",
       " '걸즈': 24904,\n",
       " '□': 154,\n",
       " '한예린': 26774,\n",
       " '지르': 7847,\n",
       " '안토니오': 20078,\n",
       " '동양': 7229,\n",
       " '개별': 20182,\n",
       " '안일': 16952,\n",
       " '언터쳐블': 24613,\n",
       " '아르세우스': 26861,\n",
       " '밴드': 9194,\n",
       " '믺': 1562,\n",
       " '스틸러': 18056,\n",
       " '듨': 1165,\n",
       " '街': 527,\n",
       " '##여행': 19766,\n",
       " '뻔뻔': 7862,\n",
       " '끝날': 9984,\n",
       " '갈구': 17430,\n",
       " 'iptv': 20144,\n",
       " '괴로운': 16758,\n",
       " '했다': 20801,\n",
       " '시다': 23492,\n",
       " '##gend': 24085,\n",
       " '1989': 26723,\n",
       " '참전': 17060,\n",
       " '식욕': 23499,\n",
       " '쓰러지': 12402,\n",
       " '변신': 7884,\n",
       " '구한': 15656,\n",
       " '##ob': 16509,\n",
       " '회귀': 23995,\n",
       " '유혜리': 27195,\n",
       " '여주인공': 5583,\n",
       " '##이영화': 26295,\n",
       " '아메리카': 12285,\n",
       " '노무현': 11100,\n",
       " '##샬': 3667,\n",
       " '시고': 16317,\n",
       " '참치': 25963,\n",
       " '팎': 2953,\n",
       " '잘사': 17009,\n",
       " '이영화': 6536,\n",
       " '##떽': 3926,\n",
       " '외숙모': 27263,\n",
       " '위쇼': 23647,\n",
       " '헷갈리': 11911,\n",
       " '해낼': 17868,\n",
       " '홍금': 9086,\n",
       " '김민선': 17257,\n",
       " '려는지': 8901,\n",
       " '다면서요': 26865,\n",
       " '##재석': 11697,\n",
       " '부딪': 12845,\n",
       " '무거': 10517,\n",
       " '대명사': 14278,\n",
       " '강했': 11929,\n",
       " '마감': 15240,\n",
       " '비견': 16890,\n",
       " '읻': 2343,\n",
       " '구지': 9109,\n",
       " '전적': 14879,\n",
       " '구먼': 9239,\n",
       " 'k': 79,\n",
       " '활': 3134,\n",
       " '거침없이': 13558,\n",
       " '오글오글': 7713,\n",
       " '고준희': 15594,\n",
       " '깨워': 21494,\n",
       " '구지성': 14620,\n",
       " '말릴': 23242,\n",
       " '콘스탄틴': 24780,\n",
       " '야설': 18479,\n",
       " '##듦': 5025,\n",
       " '##핳': 4435,\n",
       " '고생': 6214,\n",
       " '##걸이': 13835,\n",
       " 'TH': 13926,\n",
       " 'セ': 250,\n",
       " '막론': 20352,\n",
       " '선남선녀': 22822,\n",
       " '마동석': 11251,\n",
       " '뎋': 1094,\n",
       " '테스트': 10792,\n",
       " '코폴라': 14926,\n",
       " '미식': 23300,\n",
       " '외상': 25723,\n",
       " '발끝': 15262,\n",
       " '이번': 5730,\n",
       " '살인자': 10059,\n",
       " '장엄': 14101,\n",
       " '홨': 3137,\n",
       " '자네': 14865,\n",
       " '##ear': 15947,\n",
       " '##놀이': 15988,\n",
       " '뢰': 1375,\n",
       " '막장': 5341,\n",
       " '총각': 14127,\n",
       " '조리': 17766,\n",
       " '왝': 2248,\n",
       " '더만': 6273,\n",
       " '라지만': 6367,\n",
       " '주변인': 12722,\n",
       " '귀여울': 21001,\n",
       " 'ミ': 267,\n",
       " '첫눈': 17804,\n",
       " '립싱': 21632,\n",
       " '석': 1855,\n",
       " '복잡': 6542,\n",
       " '뒀': 1147,\n",
       " '노이': 11269,\n",
       " '웃기': 5337,\n",
       " '가레스베일': 21255,\n",
       " '##현경': 12696,\n",
       " '퐠': 3011,\n",
       " '아님': 5573,\n",
       " '장인': 9556,\n",
       " '스필버그': 8180,\n",
       " '늠': 1006,\n",
       " '럤': 1322,\n",
       " '에어컨': 15557,\n",
       " '##왜': 3877,\n",
       " '정원': 22031,\n",
       " '##ner': 24073,\n",
       " '저질러도': 24687,\n",
       " '신이치': 25555,\n",
       " '미안': 5827,\n",
       " '풍경화': 26634,\n",
       " '정지영': 26898,\n",
       " '재미나': 7449,\n",
       " '##버린': 6807,\n",
       " '질렌할': 18142,\n",
       " '첨단': 16429,\n",
       " '김태우': 17272,\n",
       " '배용': 15263,\n",
       " '##고기': 8594,\n",
       " '##팜': 3970,\n",
       " '선지': 19358,\n",
       " '구요': 5850,\n",
       " '막막': 13064,\n",
       " '넼ㅋㅋㅋ': 20267,\n",
       " '숨결': 21820,\n",
       " '##뺀': 4341,\n",
       " '트렌드': 14647,\n",
       " '##윙': 4813,\n",
       " '그레': 10722,\n",
       " '오노': 16978,\n",
       " '들개': 21592,\n",
       " '이등': 21980,\n",
       " '날카롭': 16656,\n",
       " '##이쁨': 24069,\n",
       " '##애': 3351,\n",
       " '예고편': 5880,\n",
       " '과감': 9371,\n",
       " '선명': 14043,\n",
       " '야만': 14436,\n",
       " '러쉬': 15232,\n",
       " '큼': 2841,\n",
       " '헬기': 9935,\n",
       " '솝': 1907,\n",
       " '의아': 10771,\n",
       " '아베': 16328,\n",
       " '비용': 10641,\n",
       " '아휴': 10649,\n",
       " '불교': 11456,\n",
       " '##레이크': 21019,\n",
       " '브레이킹': 21134,\n",
       " '가디언': 21398,\n",
       " '##뺑': 4572,\n",
       " '심하': 5887,\n",
       " '주목': 9017,\n",
       " '민영화': 11445,\n",
       " '거시': 22981,\n",
       " '종반': 22053,\n",
       " '고여': 22999,\n",
       " '다코타패닝': 16097,\n",
       " '성문화': 23450,\n",
       " '##킥': 4182,\n",
       " '차려': 9930,\n",
       " '##시네마': 16531,\n",
       " '워': 2282,\n",
       " '무서워하': 14228,\n",
       " '신랑': 11811,\n",
       " '무덤덤': 15097,\n",
       " '##어든': 20851,\n",
       " '상외': 21784,\n",
       " '장애': 6371,\n",
       " '##U': 4158,\n",
       " '##전쟁': 22309,\n",
       " '쀍': 1797,\n",
       " '아저씨': 5938,\n",
       " '날아오': 24411,\n",
       " '우사': 25734,\n",
       " '##｀': 4976,\n",
       " '폐인': 13181,\n",
       " '매국노': 15125,\n",
       " '##그래': 10245,\n",
       " '재산': 15854,\n",
       " '##스카': 9152,\n",
       " '김경': 19152,\n",
       " '아오이유우': 12516,\n",
       " '국영': 24956,\n",
       " '던짐': 25102,\n",
       " '##크만': 22295,\n",
       " '##uck': 11362,\n",
       " 'we': 12324,\n",
       " '장이': 14871,\n",
       " '신혜': 16943,\n",
       " '류담': 25216,\n",
       " '토미노': 26835,\n",
       " '레기': 8172,\n",
       " '닊': 1019,\n",
       " '귀요': 9287,\n",
       " '반개': 6294,\n",
       " '밴': 1596,\n",
       " '에드리언': 24617,\n",
       " '마운': 21636,\n",
       " '슉': 1962,\n",
       " '쇼핑': 14805,\n",
       " '스튜디오': 19999,\n",
       " '순진무구': 26800,\n",
       " '개콘': 7489,\n",
       " '재치': 9767,\n",
       " '빂': 1716,\n",
       " '독특': 5683,\n",
       " '이연': 6082,\n",
       " '박사': 8999,\n",
       " '세라': 14801,\n",
       " '얽혀': 18486,\n",
       " '금할': 20224,\n",
       " '한강': 22210,\n",
       " '디아즈': 11437,\n",
       " '##비안': 14526,\n",
       " '##맹이': 7545,\n",
       " '망가': 8027,\n",
       " '助': 356,\n",
       " '턀': 2878,\n",
       " '##벨트': 17194,\n",
       " '##기대': 24091,\n",
       " '##son': 24099,\n",
       " '등산': 25156,\n",
       " '양현': 25631,\n",
       " '##뷁': 4092,\n",
       " '!': 5,\n",
       " '非': 556,\n",
       " '뻉': 1756,\n",
       " '엓': 2181,\n",
       " '쓴다': 8579,\n",
       " '##부르': 13820,\n",
       " '퓬': 3029,\n",
       " '퍼시픽': 13907,\n",
       " '##드립': 14534,\n",
       " '달성': 15698,\n",
       " '##ㅜ': 3342,\n",
       " '파트너': 10959,\n",
       " '해골': 17867,\n",
       " '##워드': 7956,\n",
       " '고마울': 22533,\n",
       " '나와서': 5588,\n",
       " '틈틈이': 22809,\n",
       " '옥': 2219,\n",
       " '103': 20978,\n",
       " '항복': 26164,\n",
       " '스러워진': 26683,\n",
       " '나탈리': 11940,\n",
       " '산뜻': 12390,\n",
       " '존레': 17038,\n",
       " '종범': 20677,\n",
       " '계기': 7297,\n",
       " '배고픈': 24519,\n",
       " '연변': 25676,\n",
       " '습': 1977,\n",
       " '망하': 7113,\n",
       " '기집': 16772,\n",
       " '박인': 23312,\n",
       " '라이오넬': 27207,\n",
       " '오렌': 19458,\n",
       " '##스타': 6723,\n",
       " '요건': 23622,\n",
       " '연대': 21904,\n",
       " '##룯': 5075,\n",
       " '남훈': 18263,\n",
       " '##상스': 24139,\n",
       " '편중': 26104,\n",
       " '톱니바퀴': 27287,\n",
       " '매장': 15244,\n",
       " '앙꼬': 25613,\n",
       " '윤주': 19491,\n",
       " '그렁': 21466,\n",
       " '##캔': 4104,\n",
       " '부터': 5206,\n",
       " '하루': 6105,\n",
       " '좁': 2437,\n",
       " '적나라': 8479,\n",
       " '노후': 25053,\n",
       " '생략': 9063,\n",
       " '김도': 24987,\n",
       " '느끼': 5406,\n",
       " '떠오': 6548,\n",
       " '설렐': 25476,\n",
       " '숀빈': 25514,\n",
       " '훤': 3170,\n",
       " '##잘': 4207,\n",
       " '호노': 26195,\n",
       " '수치': 8715,\n",
       " '무너짐': 26693,\n",
       " '##ina': 21035,\n",
       " '##대기': 8112,\n",
       " '하시': 26141,\n",
       " '무뎌진': 27044,\n",
       " '미나': 13074,\n",
       " '불가': 6177,\n",
       " '##뻘': 3909,\n",
       " '놨': 972,\n",
       " '91': 15152,\n",
       " '##사이': 8892,\n",
       " '좔좔': 18571,\n",
       " '롁': 1356,\n",
       " '이수정': 14604,\n",
       " '공허': 8428,\n",
       " '끊이': 13609,\n",
       " '자아낸다': 22602,\n",
       " '겸': 635,\n",
       " '세기말': 14588,\n",
       " '북두': 23372,\n",
       " '저글': 25862,\n",
       " '메스': 20360,\n",
       " '사다': 9907,\n",
       " '펄롱': 26098,\n",
       " 'ㅡㅡ주': 26486,\n",
       " '방화': 13673,\n",
       " '구닥다리': 17395,\n",
       " '훈훈': 5840,\n",
       " '여태껏': 11560,\n",
       " '머레이': 23262,\n",
       " 'ㅡㅅ': 18189,\n",
       " '탈바꿈': 27285,\n",
       " '영창': 19455,\n",
       " '아담스': 15535,\n",
       " '작품': 5153,\n",
       " '체계': 19590,\n",
       " '홍은희': 17115,\n",
       " '소림축구': 15551,\n",
       " '처음': 5172,\n",
       " '→': 130,\n",
       " '##샵': 4900,\n",
       " '엄마': 5472,\n",
       " '연쇄': 9917,\n",
       " '떡': 1222,\n",
       " '##핏': 3957,\n",
       " '뭔가': 5288,\n",
       " '와우': 6595,\n",
       " '소스': 10754,\n",
       " '빈틈': 11626,\n",
       " '볼게요': 16279,\n",
       " '오광': 12635,\n",
       " '연휴': 19448,\n",
       " '기모': 23051,\n",
       " '딸림': 25168,\n",
       " '코알': 26031,\n",
       " '드팔': 13643,\n",
       " '비비안': 18929,\n",
       " '눅눅': 20277,\n",
       " '금융': 19138,\n",
       " '내': 895,\n",
       " '챙': 2647,\n",
       " '쏱': 2064,\n",
       " '##소년': 6234,\n",
       " '##셋': 4524,\n",
       " '쫗': 2587,\n",
       " '한텐': 8960,\n",
       " '할땐': 14946,\n",
       " '무모': 11615,\n",
       " '영향력': 16041,\n",
       " '제공': 10778,\n",
       " '망해라': 17308,\n",
       " '##깝': 3528,\n",
       " '부모': 5981,\n",
       " '코스': 7985,\n",
       " '시원': 6136,\n",
       " '조재': 10226,\n",
       " '도달': 13635,\n",
       " '폴리': 18661,\n",
       " '넝쿨': 19181,\n",
       " '##튬': 4884,\n",
       " '음양': 19497,\n",
       " '조수': 20674,\n",
       " '재미난': 10815,\n",
       " '##cc': 15447,\n",
       " '고경': 21432,\n",
       " '명우': 25275,\n",
       " 'ass': 26920,\n",
       " '했다간': 27135,\n",
       " '이수': 7421,\n",
       " '2010': 9504,\n",
       " '숟': 1930,\n",
       " '##쉬': 4163,\n",
       " '우리': 5203,\n",
       " '다뤘': 12806,\n",
       " '피폐': 17099,\n",
       " '부릉': 17616,\n",
       " '구암': 23031,\n",
       " '##춧': 4666,\n",
       " '버틸': 14771,\n",
       " '얼리': 20546,\n",
       " '출신': 7425,\n",
       " '##란도': 11538,\n",
       " '풀리': 9338,\n",
       " '##틴슨': 12949,\n",
       " '속아': 15772,\n",
       " '길이길이': 18981,\n",
       " '당나라': 21562,\n",
       " '##ite': 24364,\n",
       " '이성계': 26673,\n",
       " '##테스크': 12486,\n",
       " '조문': 14483,\n",
       " '막되': 23232,\n",
       " '완전히': 6735,\n",
       " '刀': 352,\n",
       " '이휘': 19505,\n",
       " '엮': 2194,\n",
       " '뷰': 1703,\n",
       " '##일리': 12048,\n",
       " '할려면': 15541,\n",
       " '##함': 3776,\n",
       " '강연': 16163,\n",
       " 'Ebs': 22894,\n",
       " '다이스': 16021,\n",
       " '아날': 11029,\n",
       " '겠어요': 15172,\n",
       " '葉': 521,\n",
       " '점': 2401,\n",
       " '式': 402,\n",
       " '##모리': 12249,\n",
       " '흘러나오': 11247,\n",
       " '살벌': 14798,\n",
       " '가져요': 22527,\n",
       " '개입': 17438,\n",
       " '##진호': 8894,\n",
       " '병동': 23358,\n",
       " '다가갈': 17199,\n",
       " 'OK': 22903,\n",
       " '성열': 25487,\n",
       " '좝': 2449,\n",
       " '버릴': 7175,\n",
       " '정돈': 10547,\n",
       " '들어맞': 14211,\n",
       " '덕': 1070,\n",
       " '털린': 20749,\n",
       " '아사': 23525,\n",
       " '##썌': 5074,\n",
       " '##라이즈': 8463,\n",
       " '죽여라': 21052,\n",
       " '마이클만': 22530,\n",
       " '려는데': 21017,\n",
       " '저딴': 11333,\n",
       " '인듯': 5867,\n",
       " '##식당': 24128,\n",
       " '에선': 5725,\n",
       " '윤수': 25773,\n",
       " '아임': 17668,\n",
       " '사모': 20433,\n",
       " '머물러': 22682,\n",
       " '나와야지': 15074,\n",
       " '서정': 8354,\n",
       " '##gain': 18736,\n",
       " '캡': 2759,\n",
       " '흔한': 6538,\n",
       " '어중': 23563,\n",
       " '엄청난': 5869,\n",
       " '귀요미': 9652,\n",
       " 'ㅜㅜㅜㅜㅜㅜㅜㅜㅜㅜ': 22447,\n",
       " '복희': 25384,\n",
       " '양파': 25636,\n",
       " '쳇': 2670,\n",
       " '재결합': 15607,\n",
       " '##왘': 4917,\n",
       " '##쉽': 4428,\n",
       " '마빡': 23227,\n",
       " '고질라': 9168,\n",
       " '크래쉬': 27109,\n",
       " '할': 3051,\n",
       " '핮': 3062,\n",
       " '아키': 10295,\n",
       " '&': 10,\n",
       " '舒': 514,\n",
       " '##타쿠': 8414,\n",
       " '##봐도': 8493,\n",
       " '책임져라': 18132,\n",
       " '오뉴': 25704,\n",
       " '약한': 8241,\n",
       " '강철': 10617,\n",
       " '위엄': 14094,\n",
       " '##곱': 3959,\n",
       " '볼걸': 13092,\n",
       " '절하': 17026,\n",
       " '렸': 1352,\n",
       " '줄라': 15375,\n",
       " '##픔': 4248,\n",
       " '##둬': 4388,\n",
       " '종영': 7069,\n",
       " '한효주': 10040,\n",
       " '발톱': 10287,\n",
       " '04': 12770,\n",
       " 'Y': 61,\n",
       " '종일': 9838,\n",
       " '뻣뻣': 16292,\n",
       " '##썬': 5063,\n",
       " '무간도': 7857,\n",
       " '##소드': 6477,\n",
       " '태어났': 12672,\n",
       " '덛': 1072,\n",
       " '당장': 8057,\n",
       " '원인': 9552,\n",
       " '좋아해': 17219,\n",
       " '↓': 131,\n",
       " '스리': 17655,\n",
       " '십': 1998,\n",
       " '월터': 17714,\n",
       " '가하': 18191,\n",
       " '담아': 8273,\n",
       " '＾': 3232,\n",
       " '인디언': 11900,\n",
       " '부끄럽': 7253,\n",
       " '논스톱': 14294,\n",
       " '디액션': 21596,\n",
       " '슈마허': 23484,\n",
       " '라구요': 16218,\n",
       " '대기': 17525,\n",
       " '난봉': 21511,\n",
       " 'dd': 15162,\n",
       " '정들': 22030,\n",
       " '문성': 14388,\n",
       " '비운': 12171,\n",
       " '⑦': 144,\n",
       " '아폴로': 22863,\n",
       " '부릴': 25396,\n",
       " '엠마스': 25661,\n",
       " '소화': 7574,\n",
       " '뛰쳐나': 9810,\n",
       " '고등학생': 8303,\n",
       " '으랴': 17723,\n",
       " '##세포': 9572,\n",
       " '탄탄': 5768,\n",
       " '##の': 4560,\n",
       " '몰라': 6660,\n",
       " '깬다': 13323,\n",
       " '피도': 23938,\n",
       " '볼일': 8763,\n",
       " '아까울': 6857,\n",
       " '올리': 6029,\n",
       " '부릉부릉': 18156,\n",
       " '베리모어': 21081,\n",
       " '줄일': 23758,\n",
       " '겹치': 15175,\n",
       " '##민국': 5921,\n",
       " '수정': 8714,\n",
       " '혓': 3115,\n",
       " '맘': 1447,\n",
       " '뭣': 1541,\n",
       " '더이다': 12810,\n",
       " '달력': 18278,\n",
       " '데자뷰': 27178,\n",
       " '녁': 945,\n",
       " '##윈튼': 18788,\n",
       " '레파': 19231,\n",
       " '마더': 13063,\n",
       " '간극': 20166,\n",
       " '레퀴': 23203,\n",
       " '련지': 16224,\n",
       " '어지러운': 18864,\n",
       " '화물': 19694,\n",
       " '김갑': 16184,\n",
       " '반하': 12833,\n",
       " '밝혀졌': 16624,\n",
       " '스웨이': 23489,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab check\n",
    "tokenizer_for_load.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# special token check\n",
    "tokenizer_for_load.all_special_tokens # 추가하기 전 기본적인 special token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check special tokens : ['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]', '[BOS]', '[EOS]', '[UNK0]', '[UNK1]', '[UNK2]', '[UNK3]', '[UNK4]', '[UNK5]', '[UNK6]', '[UNK7]', '[UNK8]', '[UNK9]', '[unused0]', '[unused1]', '[unused2]']\n"
     ]
    }
   ],
   "source": [
    "# tokenizer에 special token 추가\n",
    "special_tokens_dict = {'additional_special_tokens': user_defined_symbols}\n",
    "tokenizer_for_load.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# check tokenizer vocab with special tokens\n",
    "print('check special tokens : %s'%tokenizer_for_load.all_special_tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer_model_special\\\\tokenizer_config.json',\n",
       " 'tokenizer_model_special\\\\special_tokens_map.json',\n",
       " 'tokenizer_model_special\\\\vocab.txt',\n",
       " 'tokenizer_model_special\\\\added_tokens.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save tokenizer model with special tokens\n",
    "tokenizer_for_load.save_pretrained(hf_model_path+'_special')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check special tokens : ['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]', '[BOS]', '[EOS]', '[UNK0]', '[UNK1]', '[UNK2]', '[UNK3]', '[UNK4]', '[UNK5]', '[UNK6]', '[UNK7]', '[UNK8]', '[UNK9]', '[unused0]', '[unused1]', '[unused2]']\n",
      "vocab size : 27305\n",
      "Tokens (str)      : ['[CLS]', '나', '##는', '오늘', '아침', '##밥', '##을', '먹', '##었다', '.', '[SEP]']\n",
      "Tokens (int)      : [2, 875, 3288, 5446, 6142, 3380, 3653, 1474, 17171, 18, 3]\n",
      "Tokens (attn_mask): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check special tokens\n",
    "from transformers import BertTokenizerFast\n",
    "tokenizer_check = BertTokenizerFast.from_pretrained(hf_model_path+'_special')\n",
    "\n",
    "print('check special tokens : %s'%tokenizer_check.all_special_tokens[:20])\n",
    "\n",
    "print('vocab size : %d' % tokenizer_check.vocab_size)\n",
    "tokenized_input_for_pytorch = tokenizer_check(\"나는 오늘 아침밥을 먹었다.\", return_tensors=\"pt\")\n",
    "tokenized_input_for_tensorflow = tokenizer_check(\"나는 오늘 아침밥을 먹었다.\", return_tensors=\"tf\")\n",
    "\n",
    "print(\"Tokens (str)      : {}\".format([tokenizer_check.convert_ids_to_tokens(s) for s in tokenized_input_for_pytorch['input_ids'].tolist()[0]]))\n",
    "print(\"Tokens (int)      : {}\".format(tokenized_input_for_pytorch['input_ids'].tolist()[0]))\n",
    "print(\"Tokens (attn_mask): {}\\n\".format(tokenized_input_for_pytorch['attention_mask'].tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# test to tf&pytorch bert model\n",
    "from transformers import TFBertModel, BertModel\n",
    "\n",
    "# load a BERT model for TensorFlow and PyTorch\n",
    "model_tf = TFBertModel.from_pretrained('bert-base-cased')\n",
    "model_pt = BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final layer output shape : torch.Size([1, 11, 768])\n",
      "\n",
      "torch vs tf 결과차이\n",
      "   => last_hidden_state differences: 1.1779e-06\n",
      "   => pooler_output differences: 6.1418e-06\n"
     ]
    }
   ],
   "source": [
    "## tf vs torch bert output\n",
    "# transformers generates a ready to use dictionary with all the required parameters for the specific framework.\n",
    "input_tf = tokenizer_check(\"나는 오늘 아침밥을 먹었다.\", return_tensors=\"tf\")\n",
    "input_pt = tokenizer_check(\"나는 오늘 아침밥을 먹었다.\", return_tensors=\"pt\")\n",
    "\n",
    "# Let's compare the outputs\n",
    "output_tf, output_pt = model_tf(input_tf), model_pt(**input_pt)\n",
    "\n",
    "print('final layer output shape : %s'%(output_pt['last_hidden_state'].shape,))\n",
    "\n",
    "# Models outputs 2 values (The value for each tokens, the pooled representation of the input sentence)\n",
    "# Here we compare the output differences between PyTorch and TensorFlow.\n",
    "\n",
    "print('\\ntorch vs tf 결과차이')\n",
    "for name in [\"last_hidden_state\", \"pooler_output\"]:\n",
    "    print(\"   => {} differences: {:.5}\".format(name, (output_tf[name].numpy() - output_pt[name].detach().numpy()).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
